% Complete case and other scenarios
For the analysis on sensitivity of \ac{OLS} results to different imputation method we compare the complete-case analysis to four imputation methods. For the complete-case analysis, we drop all observations which have missing value. For the analysis on the impute data, we impute the missing values in the outcomes and covariates with the \ac{kNN} method or with a random draw from a normal distribution or simply the minimum or maximum of the respective variable. In the following, we first introduce these two methods in more detail and then present the different imputations, conducted for our sensitivity analysis the \ac{OLS} results. in the last paragraph on this section we state our expected hypothesis for the conducted imputation designs.

% kNN
The \ac{kNN} imputation method is completing missing values using the observation which has the smallest distance to itself. Thereby, the Euclidean distance is used to specify the nearest observation. If the nearest neighbor is specified and has as well a missing for the same value, then the second nearest neighbor is taken. Hence, if an observation has more than one missing, the nearest neighbor for each missing might be different. In case all observations are missing for the observations, the average of the respective sample is taken. If one observation has the same distance to all of the remaining observations, the next observations by order is taken. To account for the difference scales of the variables, the variables are normalized. After completing the missings, the values are converted back to their original scales. In this analysis, we divide in the \kNN} imputation method between the treatment and control group, i.e., the missings in the treatment group are filled by neighbors from the treatment group and the missings in the control group are filled by the neighbors in the control group. \\
The function for the imputation uses the package StandardScaler from the sklearn.preprocessing, to normalize the varaibels and  KNNImputer package from the sklearn.impute, to complete the missing with the nearest neighbor.

% MSD
The second method is completing the missings by drawing from a normal distribution whereby the mean equals the median of the respective variable/ column and the standard deviation equals a quarter of the standard deviation of each column respectively. The number of draws can be chosen. Then the mean of the random draws are imputed. For out analysis, we use only one draw. As in the \ac{kNN} imputation, we divide between the treatment and control groups. The missings are completed by the normal distribution defined by the variable median and one forth of the standard deviation of the respective variable in the respective group.

% MIN MAX
The remaining imputation methods, complete the missings by simply imputing the minimum or maximum of a variable, respectively. Again, as explained above, for the imputation we differentiate between the treatment and control group. Missings in both groups are imputed separately, based on the minimum and maximum of the respective variable, in the respective sample group.

% SCENARIOS
Based on the imputation methods explained above, we design four scenarios, the way we impute data, additionally to the complete-case analysis. The imputation of the missings in the outcomes and covariates are conducted as follows.

\begin{itemize}
	\item[1.] In the fist scenario, we impute the missings in the outcomes and covariates with the \ac{kNN} imputation method.
	\item[2.] In the second scenario, we impute the missings in the outcomes with a random draw from a normal distribution, as explained above in the first step. In the second step, we impute the missings in the covariates with the \ac{kNN} method.
	\item[3.] In the third scenario, we impute the missings in the outcomes with the minimum, as explained above in the first step. In the second step, we impute the missings in the covariates with the \ac{kNN} method.
	\item[4.] In the fourth scenario, we impute the missings in the outcomes with the maximum, as explained above in the first step. In the second step, we impute the missings in the covariates with the \ac{kNN} method.
\end{itemize}

From now on, we refer to these imputation scenarios as, ``kNN scenario'', ``kNN-msd scenario'', ``kNN-min scenario'' and ``kNN-max scenario'', respectively.

% HYPOTHESIS
For the four different imputation designs, we established three main hypothesis:

\begin{itemize}

	\item[H1] In the ``kNN'' case we hypothezise that there will not be a notable change in the treatment coefficient, ``Treatment'' and the standard deviation for all estimates decreases. The first part of the hypothesis is based on the analysis on the missings. The analysis on the missings has shown that the missings are possibly generated based on the \ac{MAR}, i.e., they correlate with observed characteristics. Hence, imputing the missings based on the observed information should not change the estimation on the treatment. We expect the standard error to decrease because we impute from the same available sample and hence distribution and because the sample size increases with imputation.

	\item[H2] In the ``kNN-msd scenario'' we hypothize that the treatment effect, ``Treatment'' decreases and that standard errors of the estimates decrease. We expect the treatment effect to decrease because most of the missings are observed in the control group and for people with lower income levels see section 3.2, Table~\ref{tab:table_missing}. Through the imputation of the outcome variable, household income in the second wave, with the median plus, minus some noise, leads to possibly better values for the ones who dropped out or did not provide information on the outcome. This leads to the fact that the imputation decreases the difference between the treatment and control group on the outcome

	\item[H3]

\end{itemize}


The treatment effect in the ``kNN scenario'' will decrease incompared to the complete-case analysis, we expect the following. The missings in the outcome variable, household income from the second wave, are imputed with t

in line with what someone would expect. The imputed values for the covarites are based on observations already in the sample and the outcome is imputed with the median plus, minus some small random noise. With this

In the following we present our expectations for each outcome of the analysis on the imputed data, the ``kNN scenario'', ``kNN-msd scenario'', ``kNN-max scenario'' and ``kNN-min scenario''.

We expect the treatment in the ``kNN scenario'' to decrease compared to the complete-case analysis because. observations with missing information are mostly from the control group




