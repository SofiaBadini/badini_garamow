\section{Introduction}

% MOTIVATION: 

% RCTs
\acp{RCT} are widely used in economics, especially in the context of policy evaluation. The random assignment of the population of interest into treatment and control groups eliminates the selection bias. For this reason the \ac{RCT} is sometimes referred to as the ``golden standard'' of the evaluation methods. 
However, its validity can be threatened by missing covariate and outcome data due to non-response or attrition in the follow up surveys.\footnote{See \cite{angrist_mostly_2008} for further discussion.} Incomplete data becomes a problem in case there is evidence that missing observations follow a pattern/ observations are missing in a non-random way. Hence, the remaining sample might not be representative. Individuals who are not willing to provide relevant information or participate in all follow-up surveys might be systematically different from the individuals who provide full information and participate in all follow up surveys. Consequently, handling missing data inappropriately might lead to biased results \citep{heckman1976common, lee2009training, kling2007experimental}. 
%However, to estimate treatment effects \acp{RCT} rely on panel data and therefore are, in many cases, impractical.

% TYPE OF MISSINGS IN THE LITERATURE
\cite{little1989analysis} differentiate between three missing data mechanisms: (1) data missing at completely random (MCAR), (2) data missing at random, and (3) data missing at non random. Data missing at completely random is unrelated to observed and unobserved characteristics, data missing at random is only related to observed characteristics, and data missing at not random is related to both observed and unobserved characteristics. Because it is impossible to assign the available data to one of the three missing data mechanisms with certainty, collected information on the missing data can be used to come up with reasonable assumptions on the missing data. 

Based on the underlying mechanism there are different ways to handle missing data: (1) complete case analysis, (2) single imputation, and (3) multiple imputation. However, if the assumed underlying missing data mechanism is incorrect, the result may still be biased (Li et al., 2014). 

% Sentivity analysis is good:
Therefore, in order to make reasonable statements on the estimated results, the missing data problem requires a sensitivity analysis which varies the assumptions about the missing data and considers the different methods to handle missing data.

To analyze 

, we perform a sensitivity analysis on estimated treatment effects, varying the methods to handle missing data. All outcomes under the different methods are compared to complete case analysis in which attrition is ignored. 

% GATE
For this purpose, we make use of the policy evaluation of the ``\ac{GATE}'' project by Fairlie et al. (2015). The authors estimate the effect of the \ac{GATE} project, a subsidized entrepreneurship training in the USA on \textcolor{red}{INPUT SOFIA}. The project provides a notable example for the data missing problem because \textcolor{red}{INPUT SOFIA}.



% METHODS IN USE IN LITERATURE
The current literature offers several methods on how to approach non-random missing data to achieve consistent estimates \textcolor{red}{INPUT ADELINA}.

% OUR ANALYSIS IN DETAIL
In our analysis we focus of the complete case analysis and the single imputation approach. 

%Researchers’ reluctance to rely upon speciﬁc exclusion restrictions motivates an alternative ap
%proach. This approach utilizes boundedness of the support of the outcome variable in order to construct
%“worst-case” bounds for the treatment effect parameter – bounds that are still consistent with the data that
%are observed

\textcolor{red}{Reference to assumptions and missing data methods mentioned above to be made here.}

% MISSINGS NON-RESPONSE
% return to baseline, different assumptions about the outcome variabels
For missings we apply three different methods. First, as in the paper, we drop observations that reveal missing information of relevant variablese. Scond, we follow the ``hot-deck'' procedure in the paper (Fairlie et al. (2015)). Second, we extend the analysis by the ``nearest neighbor'' procedure to contrast the results in the paper. 

% ATTRITION
% last observation carried forward, mean +- sd1, Inverse probability Weights, return to baseline
For the attrition\footnote{In this paper we focus on ``ex-post'' attrition methods to  since ``ex-ante'' approaches require tracking which usually bears large costs.} we replicate the three different methods which are used in the paper. First, as the authors, we ignore attrition, estimating the effects on the remaining sample. Second, we replace a missing individual with the average individual in the group and add some noise to it such that the replacement resembles a random draw from a normal distribution around the group mean. Third, we assume that the attrition is driven by selection on observables and apply the \ac{IPW} method. Finally, we compare the outcomes of the different methods. 
